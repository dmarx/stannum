<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Tube - Stannum</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="../highlight.css">
        <link rel="stylesheet" href="../tomorrow-night.css">
        <link rel="stylesheet" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "../";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="../introduction.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="../tin.html"><strong aria-hidden="true">2.</strong> Tin</a></li><li class="chapter-item expanded "><a href="../tube/basics.html" class="active"><strong aria-hidden="true">3.</strong> Tube</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="../tube/advanced_field_construction.html"><strong aria-hidden="true">3.1.</strong> Advanced Field Construction</a></li><li class="chapter-item expanded "><a href="../tube/dynamic_dimensions.html"><strong aria-hidden="true">3.2.</strong> Dynamic Dimensions</a></li></ol></li><li class="chapter-item expanded "><a href="../complex_numbers.html"><strong aria-hidden="true">4.</strong> Complex Numbers</a></li><li class="chapter-item expanded "><a href="../contribution.html"><strong aria-hidden="true">5.</strong> Contribution</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Stannum</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="tube"><a class="header" href="#tube">Tube</a></h1>
<p><code>Tube</code>, compared to <code>Tin</code>, helps you:</p>
<ul>
<li>create necessary fields</li>
<li>manage fields</li>
<li>(optionally) do automatic batching</li>
<li>(optionally) create fields and tensors of which shapes are dynamically calculated. For example, the case in convolution.</li>
</ul>
<p>So, <code>Tube</code> is more flexible and convenient, but it also introduces some overhead.</p>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>All you need to do is to register:</p>
<ul>
<li>Input/intermediate/output <strong>tensor shapes</strong> instead of fields</li>
<li>At least one kernel that takes the following as arguments
<ul>
<li>Taichi fields: correspond to tensors (may or may not require gradients)</li>
<li>(Optional) Extra arguments: will NOT receive gradients
<ul>
<li>see below <a href="basics.html#Set-Kernel-Extra-Arguments">Set Kernel Arguments</a></li>
</ul>
</li>
</ul>
</li>
<li>(Optional) Tweak field creation, providing a <code>FieldManager</code>, see <a href="advanced_field_construction.html">Advanced Field Construction</a></li>
<li>(Optional) Dynamically calculate the shape of fields and tensors, providing a <code>DimensionCalculator</code>, see <a href="dynamic_dimensions.html">Dynamic Dimension Calculation</a></li>
</ul>
<h2 id="requirements"><a class="header" href="#requirements">Requirements</a></h2>
<p>Registration order: Input tensors/intermediate fields/output tensors must be registered first, and then kernel.</p>
<p>When registering a kernel, a list of field/tensor names is required, for example, the above <code>[&quot;arr_a&quot;, &quot;arr_b&quot;, &quot;output_arr&quot;]</code>.</p>
<p>This list should correspond to the fields in the arguments of a kernel (e.g., below <code>ti_add()</code>).</p>
<p>The order of input tensors should match the input fields of a kernel.</p>
<p>A valid example is shown below:</p>
<pre><code class="language-python">@ti.kernel
def ti_add(arr_a: ti.template(), arr_b: ti.template(), output_arr: ti.template()):
    for i in arr_a:
        output_arr[i] = arr_a[i] + arr_b[i]

ti.init(ti.cpu)
cpu = torch.device(&quot;cpu&quot;)
a = torch.ones(10)
b = torch.ones(10)
tube = Tube(cpu) \
    .register_input_tensor((10,), torch.float32, &quot;arr_a&quot;, False) \
    .register_input_tensor((10,), torch.float32, &quot;arr_b&quot;, False) \
    .register_output_tensor((10,), torch.float32, &quot;output_arr&quot;, False) \
    .register_kernel(ti_add, [&quot;arr_a&quot;, &quot;arr_b&quot;, &quot;output_arr&quot;]) \
    .finish()
out = tube(a, b)
</code></pre>
<p>Acceptable dimensions of tensors to be registered are:</p>
<ul>
<li><code>stannum.BatchDim</code>: means the flexible batch dimension, must be the first dimension e.g. <code>(BatchDim, 2, 3, 4)</code></li>
<li>Positive integers: fixed dimensions with the indicated dimensionality</li>
<li><code>stannum.AnyDim</code>: means any number <code>[1, +inf)</code>, <strong>only usable</strong> in the registration of input tensors.</li>
<li><code>stannum.MatchDim(dim_id: str | int)</code>: means some dimensions with the same <code>dim_id</code> must be of the same dimensionality
<ul>
<li>Restriction: <code>MatchDim</code> must be &quot;declared&quot; in the registration of input tensors first, then used in the registration of intermediate and output tensors. </li>
<li>Example: tensor <code>a</code> and <code>b</code> of shapes <code>a: (2, MatchDim(&quot;some_dim&quot;), 3)</code> and <code>b: (MatchDim(&quot;some_dim&quot;), 5, 6)</code> mean the dimensions of <code>some_dim</code> must match, that is, the second dimension of <code>a</code> must match the first dimension of <code>b</code>.</li>
</ul>
</li>
</ul>
<h2 id="automatic-batching"><a class="header" href="#automatic-batching">Automatic Batching</a></h2>
<p>Automatic batching is done simply by running kernels <code>batch</code> times. The batch number is determined by the leading dimension of tensors of registered shape <code>(None, ...)</code>.</p>
<p>It's required that if any input tensors are batched (which means they have registered the first dimension to be <code>None</code>), all intermediate fields and output tensors must be registered as batched.</p>
<h2 id="more-examples"><a class="header" href="#more-examples">More Examples</a></h2>
<p>Simple one without negative indices or batch dimension:</p>
<pre><code class="language-python">@ti.kernel
def ti_add(arr_a: ti.template(), arr_b: ti.template(), output_arr: ti.template()):
    for i in arr_a:
        output_arr[i] = arr_a[i] + arr_b[i]

ti.init(ti.cpu)
cpu = torch.device(&quot;cpu&quot;)
a = torch.ones(10)
b = torch.ones(10)
tube = Tube(cpu) \
    .register_input_tensor((10,), torch.float32, &quot;arr_a&quot;, False) \
    .register_input_tensor((10,), torch.float32, &quot;arr_b&quot;, False) \
    .register_output_tensor((10,), torch.float32, &quot;output_arr&quot;, False) \
    .register_kernel(ti_add, [&quot;arr_a&quot;, &quot;arr_b&quot;, &quot;output_arr&quot;]) \
    .finish()
out = tube(a, b)
</code></pre>
<p>With dimension matching:</p>
<pre><code class="language-python">ti.init(ti.cpu)
cpu = torch.device(&quot;cpu&quot;)
tube = Tube(cpu) \
.register_input_tensor((MatchDim(0),), torch.float32, &quot;arr_a&quot;, False) \
.register_input_tensor((MatchDim(0),), torch.float32, &quot;arr_b&quot;, False) \
.register_output_tensor((MatchDim(0),), torch.float32, &quot;output_arr&quot;, False) \
.register_kernel(ti_add, [&quot;arr_a&quot;, &quot;arr_b&quot;, &quot;output_arr&quot;]) \
.finish()
dim = 10
a = torch.ones(dim)
b = torch.ones(dim)
out = tube(a, b)
assert torch.allclose(out, torch.full((dim,), 2.))
dim = 100
a = torch.ones(dim)
b = torch.ones(dim)
out = tube(a, b)
assert torch.allclose(out, torch.full((dim,), 2.))

</code></pre>
<p>With batch dimension:</p>
<pre><code class="language-python">@ti.kernel
def int_add(a: ti.template(), b: ti.template(), out: ti.template()):
    out[None] = a[None] + b[None]

ti.init(ti.cpu)
b = torch.tensor(1., requires_grad=True)
batched_a = torch.ones(10, requires_grad=True)
tube = Tube() \
.register_input_tensor((BatchDim,), torch.float32, &quot;a&quot;) \
.register_input_tensor((), torch.float32, &quot;b&quot;) \
.register_output_tensor((BatchDim,), torch.float32, &quot;out&quot;, True) \
.register_kernel(int_add, [&quot;a&quot;, &quot;b&quot;, &quot;out&quot;]) \
.finish()
out = tube(batched_a, b)
loss = out.sum()
loss.backward()
assert allclose(torch.ones_like(batched_a) + 1, out)
assert b.grad == 10.
assert allclose(torch.ones_like(batched_a), batched_a.grad)
</code></pre>
<p>For more valid and invalid use examples, please see <a href="../../../tests/test_tube">test files</a> in the test folder.</p>
<h2 id="apis"><a class="header" href="#apis">APIs</a></h2>
<h3 id="constructor"><a class="header" href="#constructor">Constructor</a></h3>
<pre><code class="language-python">def __init__(self,
             device: Optional[torch.device] = None,
             persistent_field: bool = True,
             enable_backward: bool = True):
    &quot;&quot;&quot;
        Init a tube

        @param device: Optional, torch.device tensors are on, if it's None, the device is determined by input tensors
        @param persistent_field: whether or not to save fields during forward pass.
        If True, created fields will not be destroyed until compute graph is cleaned,
        otherwise they will be destroyed right after forward pass is done and re-created in backward pass.
        Having two modes is due to Taichi's performance issue, see https://github.com/taichi-dev/taichi/pull/4356
        @param enable_backward: whether or not to enable backward gradient computation, disable it will have performance
        improvement in forward pass, but attempting to do backward computation will cause runtime error.
        &quot;&quot;&quot;
</code></pre>
<h3 id="registrations"><a class="header" href="#registrations">Registrations</a></h3>
<p>Register input tensor shapes:</p>
<pre><code class="language-python">def register_input_tensor(self,
                          dims: Tuple[DimOption] | List[DimOption],
                          dtype: torch.dtype,
                          name: str,
                          requires_grad: Optional[bool] = None,
                          field_manager: Optional[FieldManager] = None):
    &quot;&quot;&quot;
        Register an input tensor

        @param dims: dims can contain `None`, positive and negative numbers,
        for restrictions and requirements, see README
        @param dtype: torch data type
        @param name: name of the tensor and corresponding field
        @param requires_grad: optional, if it's None, it will be determined by input tensor
        @param field_manager: customized field manager, if it's None, a DefaultFieldManger will be used
        &quot;&quot;&quot;

</code></pre>
<p>Register intermediate field shapes:</p>
<pre><code class="language-python">def register_intermediate_field(self,
                                dims_or_calc: Tuple[DimOption] | List[DimOption] | Callable | DimensionCalculator,
                                ti_dtype: TiDataType,
                                name: str,
                                needs_grad: bool,
                                field_manager: Optional[FieldManager] = None):
    &quot;&quot;&quot;
        Register an intermediate field,
        which can be useful if multiple kernels are used and intermediate results between kernels are stored

        @param dims_or_calc: dims can contain `None`, positive and negative numbers,
        for restrictions and requirements, see README; Or DimensionCalculator instance or a function can be passed
        to dynamically calculate dimensions
        @param ti_dtype: taichi data type
        @param name: name of the field
        @param needs_grad: if the field needs gradients.
        @param dims: dims can contain `None`, positive and negative numbers,
        for restrictions and requirements, see README
        @param dim_calc: DimensionCalculator instance or a function
        @param field_manager: customized field manager, if it's None, a DefaultFieldManger will be used
        &quot;&quot;&quot;
</code></pre>
<p>Register output tensor shapes:</p>
<pre><code class="language-python">def register_output_tensor(self,
                           dims_or_calc: Tuple[DimOption] | List[DimOption] | Callable | DimensionCalculator,
                           dtype: torch.dtype,
                           name: str,
                           requires_grad: bool,
                           field_manager: Optional[FieldManager] = None):
    &quot;&quot;&quot;
        Register an output tensor

        @param dims_or_calc: dims can contain `None`, positive and negative numbers,
        for restrictions and requirements, see README; Or DimensionCalculator instance or a function can be passed
        to dynamically calculate dimensions
        @param dtype: torch data type
        @param name: name of the tensor and corresponding field
        @param dims: dims can contain `None`, positive and negative numbers,
        for restrictions and requirements, see README
        @param dim_calc: DimensionCalculator instance or a function
        @param requires_grad: if the output requires gradients
        @param field_manager: customized field manager, if it's None, a DefaultFieldManger will be used
        &quot;&quot;&quot;
</code></pre>
<p>Register kernels:</p>
<pre><code class="language-python">def register_kernel(self, kernel: Callable, tensor_names: List[str], *extra_args: Any, name: Optional[str] = None):
    &quot;&quot;&quot;
        Register a Taichi kernel

        @param kernel: Taichi kernel. For requirements, see README
        @param tensor_names: the names of registered tensors that are to be used in this kernel
        @param extra_args: any extra arguments passed to the kernel
        @param name: name of this kernel, if it's None, it will be kernel.__name__
        &quot;&quot;&quot;
</code></pre>
<h3 id="set-kernel-extra-arguments"><a class="header" href="#set-kernel-extra-arguments">Set Kernel Extra Arguments</a></h3>
<p>Kernels may need extra arguments that do not need gradients, then you can set extra arguments with <code>Tube.set_kernel_extra_args()</code> or set extra arguments in <code>Tube.register_kernel()</code></p>
<pre><code class="language-python">def set_kernel_extra_args(self, kernel: Callable | str, *extra_args: Any):
    &quot;&quot;&quot;
        Set args for a kernel
        @param kernel: kernel function or its name
        @param extra_args: extra kernel arguments
        &quot;&quot;&quot;
</code></pre>
<p>One example kernel is shown below, in which <code>multiplier</code> is an extra kernel argument.</p>
<pre><code class="language-python">@ti.kernel
def mul(arr: ti.template(), out: ti.template(), multiplier: float):
    for i in arr:
        out[i] = arr[i] * multiplier
</code></pre>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../tin.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next" href="../tube/advanced_field_construction.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../tin.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next" href="../tube/advanced_field_construction.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->


    </body>
</html>
